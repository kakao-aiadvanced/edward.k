{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c3dffb-98fa-4d14-98ef-80c38d290e1b",
   "metadata": {},
   "source": [
    "# GPT-3.5-Turbo on GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a96802ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/anaconda3/lib/python3.9/site-packages (1.34.0)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (1.9.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2022.9.24)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f7c15ca-974a-49aa-8212-d9b6730df39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def create_prompt():\n",
    "    prompt = f\"\"\"\n",
    "사용자의 질문에 대해 가장 적절한 역할(수학 교사 또는 역사 교사)을 선택하세요.\n",
    "\n",
    "1. 사용자 입력을 받습니다.\n",
    "2. 입력된 질문을 분석하여 수학 질문인지 역사 질문인지 판단합니다.\n",
    "3. 질문이 수학 관련이라면 '수학 교사'를 선택합니다.\n",
    "4. 질문이 역사 관련이라면 '역사 교사'를 선택합니다.\n",
    "5. 선택된 역할을 출력합니다.\n",
    "\n",
    "사용자 입력:\n",
    "    \"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def chat(question):\n",
    "    return ollama.chat(model='llama3', messages=[\n",
    "        {\"role\": \"system\", \"content\": create_prompt()},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae53f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수학 교사\n",
      "\n",
      "근의 공식은 a² + b² = c² 로 표현됩니다. 여기서 a와 b는 직각삼각형 내에 있는 두 변의 길이, c는 гип오탐을 지나는 변의 길입니다.\n"
     ]
    }
   ],
   "source": [
    "response = chat(\"근의 공식이 무엇인가? 한글로 답해줘.\")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
